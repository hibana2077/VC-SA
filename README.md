# VC-SA - Video Action Recognition with Graph-based Sampling

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)](https://pytorch.org/)
[![Lightning](https://img.shields.io/badge/lightning-2.0+-purple.svg)](https://lightning.ai/)
[![Code style: modular](https://img.shields.io/badge/code%20style-modular-green.svg)](docs/ARCHITECTURE.md)

é«˜æ•ˆçš„è¦–é »å‹•ä½œè­˜åˆ¥æ¡†æ¶ï¼Œæ¡ç”¨æ¨¡å¡ŠåŒ–è¨­è¨ˆï¼Œçµåˆ Vision Transformerã€å¹€/Token æ™ºèƒ½é¸æ“‡å’Œåœ–è¨˜æ†¶ç¶²çµ¡ã€‚

## âœ¨ ç‰¹è‰²

- ğŸ¯ **æ™ºèƒ½æ¡æ¨£**: è‡ªå‹•é¸æ“‡æœ€å…·ä¿¡æ¯é‡çš„å¹€å’Œ Token
- ğŸ”— **åœ–è¨˜æ†¶ç¶²çµ¡**: åŸºæ–¼åœ–çµæ§‹çš„æ™‚åºå»ºæ¨¡
- âš¡ **é«˜æ•ˆè¨“ç·´**: æ”¯æŒæ··åˆç²¾åº¦ã€æ¢¯åº¦ç´¯ç©å’Œåˆ†ä½ˆå¼è¨“ç·´
- ğŸ§© **æ¨¡å¡ŠåŒ–è¨­è¨ˆ**: æ¸…æ™°çš„ç¨‹å¼ç¢¼çµæ§‹ï¼Œæ˜“æ–¼æ“´å±•å’Œç¶­è­·
- ğŸ“Š **å®Œæ•´æµç¨‹**: å¾è³‡æ–™è¼‰å…¥åˆ°æ¨¡å‹è¨“ç·´çš„ç«¯åˆ°ç«¯è§£æ±ºæ–¹æ¡ˆ

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
VC-SA/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ run.py              # ä¸»ç¨‹å¼å…¥å£
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å¡Š
â”‚   â”‚   â”œâ”€â”€ models.py       # æ¨¡å‹æ¶æ§‹
â”‚   â”‚   â””â”€â”€ data.py         # è³‡æ–™è™•ç†
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•¸
â”‚       â”œâ”€â”€ config.py       # é…ç½®ç®¡ç†
â”‚       â””â”€â”€ video_utils.py  # è¦–é »å·¥å…·
â”œâ”€â”€ example/
â”‚   â””â”€â”€ core.py             # FrameTokenCoSelector & GraphBasedMemBank
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ idea.md             # è¨­è¨ˆç†å¿µ
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # æ¶æ§‹æ–‡æª”
â”‚   â””â”€â”€ MIGRATION.md        # é·ç§»æŒ‡å—
â””â”€â”€ requirements.txt        # ä¾è³´åˆ—è¡¨
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### æº–å‚™è³‡æ–™

å»ºç«‹ CSV æ¨™è¨»æª”æ¡ˆï¼ˆtrain.csv, val.csv, test.csvï¼‰ï¼š

```csv
video_path,label
/path/to/video1.mp4,0
/path/to/video2.avi,1
```

### è¨“ç·´æ¨¡å‹

```bash
python -m src.run \
    --data-root data/videos \
    --train-anno train.csv \
    --val-anno val.csv \
    --test-anno test.csv \
    --num-classes 400 \
    --frames-per-clip 16 \
    --frame-topk 8 \
    --token-topk 32 \
    --batch-size 2 \
    --max-epochs 50
```

### Python API ä½¿ç”¨

```python
from src.core import GraphSamplerActionModel, VideoDataModule
from src.utils import get_default_config

# å»ºç«‹è³‡æ–™æ¨¡å¡Š
datamodule = VideoDataModule(
    data_root='data/videos',
    train_csv='train.csv',
    val_csv='val.csv',
    test_csv='test.csv',
    frames_per_clip=16,
    batch_size=2,
)

# å»ºç«‹æ¨¡å‹
model = GraphSamplerActionModel(
    num_classes=400,
    frames_per_clip=16,
    frame_topk=8,
    token_topk=32,
)

# è¨“ç·´ï¼ˆä½¿ç”¨ PyTorch Lightningï¼‰
import lightning as L
trainer = L.Trainer(max_epochs=50)
trainer.fit(model, datamodule=datamodule)
```

## ğŸ“š æ–‡æª”

- [æ¶æ§‹æ¦‚è¦½](docs/ARCHITECTURE.md) - è©³ç´°çš„ç³»çµ±æ¶æ§‹èªªæ˜
- [é·ç§»æŒ‡å—](docs/MIGRATION.md) - å¾èˆŠç‰ˆæœ¬é·ç§»çš„æŒ‡å—
- [ç¨‹å¼ç¢¼æ–‡æª”](src/README.md) - æ¨¡å¡ŠåŒ–ç¨‹å¼ç¢¼èªªæ˜
- [è¨­è¨ˆç†å¿µ](docs/idea.md) - å°ˆæ¡ˆè¨­è¨ˆæ€è·¯

## ğŸ”§ ä¸»è¦æ¨¡å¡Š

### Core Modules

- **models.py**: æ¨¡å‹æ¶æ§‹å®šç¾©
  - `ViTTokenBackbone`: Vision Transformer éª¨å¹¹ç¶²çµ¡
  - `GraphSamplerActionModel`: å®Œæ•´çš„å‹•ä½œè­˜åˆ¥æ¨¡å‹

- **data.py**: è³‡æ–™è™•ç†æ¨¡å¡Š
  - `VideoDataModule`: Lightning è³‡æ–™æ¨¡å¡Š
  - `SimpleVideoDataset`: è¦–é »è³‡æ–™é›†
  - `FrameCache`: å¹€å¿«å–ç³»çµ±

### Utils Modules

- **config.py**: é…ç½®ç®¡ç†
  - `parse_args()`: å‘½ä»¤åˆ—åƒæ•¸è§£æ
  - `TrainingConfig`: é…ç½®é¡åˆ¥
  - `get_default_config()`: ç²å–é è¨­é…ç½®

- **video_utils.py**: è¦–é »è™•ç†å·¥å…·
  - `hash_path()`: è·¯å¾‘å“ˆå¸Œå‡½æ•¸

## ğŸ“ å¼•ç”¨

å¦‚æœé€™å€‹å°ˆæ¡ˆå°æ‚¨çš„ç ”ç©¶æœ‰å¹«åŠ©ï¼Œè«‹è€ƒæ…®å¼•ç”¨ã€‚

## ğŸ“„ æˆæ¬Š

[åœ¨æ­¤æ·»åŠ æˆæ¬Šè³‡è¨Š]

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è¯çµ¡

[åœ¨æ­¤æ·»åŠ è¯çµ¡è³‡è¨Š]